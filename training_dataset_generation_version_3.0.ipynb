{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_locations = ['E:/qrf/Lab Stuff/newDataset/spring-boot_labeled_sentences.csv','E:/qrf/Lab Stuff/newDataset/facebook_labeled_sentences.csv',\n",
    "                 'E:/qrf/Lab Stuff/newDataset/tensorflow_labeled_sentences.csv','E:/qrf/Lab Stuff/newDataset/vscode_labeled_sentences.csv',\n",
    "                 'E:/qrf/Lab Stuff/newDataset/flutter_labeled_sentences.csv']\n",
    "q_locations = ['E:/qrf/Lab Stuff/newDataset/spring-boot_PRs.txt','E:/qrf/Lab Stuff/newDataset/facebook_PRs.txt',\n",
    "               'E:/qrf/Lab Stuff/newDataset/tensorflow_PRs.txt','E:/qrf/Lab Stuff/newDataset/vscode_PRs.txt',\n",
    "               'E:/qrf/Lab Stuff/newDataset/flutter_PRs.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(loc1,loc2):\n",
    "    df = pd.read_csv(loc1)\n",
    "    df2 = pd.read_table(loc2, sep = ',')\n",
    "    issue_id = df.values[:,1].tolist()\n",
    "    lbl_lst = df.values[:,3].tolist()\n",
    "    all_issue = df2.values[:,1].tolist()\n",
    "    question_lst = df2.values[:,11].tolist()\n",
    "    title_lst = df2.values[:,7].tolist()\n",
    "\n",
    "    newdic = dict(zip(issue_id,lbl_lst))\n",
    "    pos_issue = list(set([i for i,j in newdic.items() if j == 0]))\n",
    "    all_neg_issue = list(set([x for x in all_issue if x not in issue_id]))\n",
    "    neg_issue = random.sample(all_neg_issue,len(pos_issue))\n",
    "    pos_question = [q for t,q,i in zip(title_lst,question_lst,all_issue) if i in pos_issue]\n",
    "    pos_title = [t for t,q,i in zip(title_lst,question_lst,all_issue) if i in pos_issue]\n",
    "\n",
    "    neg_question = [q for t,q,i in zip(title_lst,question_lst,all_issue) if i in neg_issue]\n",
    "    neg_title = [t for t,q,i in zip(title_lst,question_lst,all_issue) if i in neg_issue]\n",
    "\n",
    "    title_lst = pos_title + neg_title\n",
    "    question_lst= pos_question + neg_question\n",
    "    lable_lst = [1 for i in range(len(pos_question))] + [0 for i in range(len(neg_question))]\n",
    "    \n",
    "    return title_lst,question_lst,lable_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29907\n",
      "29907\n",
      "29907\n"
     ]
    }
   ],
   "source": [
    "title_list = []\n",
    "question_list = []\n",
    "lable_list = []\n",
    "for loc1,loc2 in zip(pos_locations,q_locations):\n",
    "    t1,q1,l1 = get_dataset(loc1,loc2)\n",
    "    title_list +=t1\n",
    "    question_list+=q1\n",
    "    lable_list+=l1\n",
    "    \n",
    "print(len(title_list))\n",
    "print(len(question_list))\n",
    "print(len(lable_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29907, 3)\n",
      "(28998, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>possible to use spring-boot on android develop...</td>\n",
       "      <td>&lt;!-- thanks for raising a spring boot issue. p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how do i use a custom websockethandler when i ...</td>\n",
       "      <td>my code is like this  ```java @configuration @...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can i use a higher version of the `spring-boot...</td>\n",
       "      <td>can i use a higher version of the `spring-boot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>webflux functional endpoints authentication</td>\n",
       "      <td>i only found the documentation about authentic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>document that the minimum supported version of...</td>\n",
       "      <td>hi, i deployed a project made with https://sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  possible to use spring-boot on android develop...   \n",
       "1  how do i use a custom websockethandler when i ...   \n",
       "3  can i use a higher version of the `spring-boot...   \n",
       "4        webflux functional endpoints authentication   \n",
       "5  document that the minimum supported version of...   \n",
       "\n",
       "                                            question  label  \n",
       "0  <!-- thanks for raising a spring boot issue. p...      1  \n",
       "1  my code is like this  ```java @configuration @...      1  \n",
       "3  can i use a higher version of the `spring-boot...      1  \n",
       "4  i only found the documentation about authentic...      1  \n",
       "5  hi, i deployed a project made with https://sta...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_question = pd.DataFrame({'title':title_list,'question': question_list,'label':lable_list})\n",
    "\n",
    "print(labeled_question.shape)\n",
    "labeled_question.dropna(axis=0,how='any',inplace=True)\n",
    "labeled_question['question'] = labeled_question['question'].str.lower()\n",
    "labeled_question['title'] = labeled_question['title'].str.lower()\n",
    "print(labeled_question.shape)\n",
    "labeled_question.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re, string, unicodedata\n",
    "from spellchecker import SpellChecker\n",
    "import wordninja\n",
    "import string\n",
    "from nltk.corpus import wordnet\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_en = list(nltk.corpus.stopwords.words('english'))\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spelling(word):\n",
    "    corrected_word = spell.correction(word)\n",
    "    return str(corrected_word)\n",
    "\n",
    "def split_words(word):\n",
    "    split_word = wordninja.split(word)\n",
    "    return ' '.join(split_word)\n",
    "\n",
    "def cleanHTML_rmStopWords_lemmatize(df):\n",
    "    df = df.apply(lambda x: expand_contractions(str(x)))\n",
    "    df = df.apply(lambda x: str(x).lower())\n",
    "    df = df.apply(lambda x: re.sub(re.compile('<.*?>'), '', str(x)))\n",
    "    df = df.apply(lambda x: re.sub('\\\\b\\\\w[\\\\w.-]*@\\\\w+\\\\.\\\\w{2,4}\\\\b', 'email address', x))\n",
    "    df = df.apply(lambda x: re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', 'url address', x))\n",
    "    df = df.apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n",
    "    df = df.apply(lambda x: ' '.join(word for word in str(x).split() if word.lower() not in stop_words_en))\n",
    "    #df = df.apply(lambda x: ' '.join(correct_spelling(word) for word in str(x).split()))\n",
    "    df = df.apply(lambda x: ' '.join(split_words(word) for word in str(x).split()))\n",
    "    df = df.apply(lambda x: re.sub(r'[^\\w\\s]+', '', x))\n",
    "    df = df.apply(lambda x: ' '.join(lemmatizer.lemmatize(word) for word in str(x).split() if len(word)>2 and wordnet.synsets(word)))\n",
    "    df = df.apply(lambda x: re.sub(' +', ' ', x))\n",
    "    return df\n",
    "\n",
    "cleaned_questions = cleanHTML_rmStopWords_lemmatize(labeled_question['question'])\n",
    "cleaned_titles = cleanHTML_rmStopWords_lemmatize(labeled_question['title'])\n",
    "cleaned_labeled_question = pd.DataFrame({'title':cleaned_titles,'body': cleaned_questions, 'label': labeled_question['label']})\n",
    "cleaned_labeled_question = cleaned_labeled_question.loc[cleaned_labeled_question['body'].str.len()>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" def html_remover(data):\\n  beauti = BeautifulSoup(data,'html.parser')\\n  return beauti.get_text()\\n\\n# to remove URL\\ndef url_remover(data):\\n  return re.sub(r'https\\\\S','',data)\\n\\ndef web_associated(data):\\n  text = html_remover(data)\\n  text = url_remover(text)\\n  return text \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def html_remover(data):\n",
    "  beauti = BeautifulSoup(data,'html.parser')\n",
    "  return beauti.get_text()\n",
    "\n",
    "# to remove URL\n",
    "def url_remover(data):\n",
    "  return re.sub(r'https\\S','',data)\n",
    "\n",
    "def web_associated(data):\n",
    "  text = html_remover(data)\n",
    "  text = url_remover(text)\n",
    "  return text \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" def remove_round_brackets(data):\\n  return re.sub('\\\\(.*?\\\\)','',data)\\n\\ndef remove_punc(data):\\n  trans = str.maketrans('','', string.punctuation)\\n  return data.translate(trans)\\n\\ndef white_space(data):\\n  return ' '.join(data.split())\\n\\ndef complete_noise(data):\\n  new_data = remove_round_brackets(data)\\n  new_data = remove_punc(new_data)\\n  new_data = white_space(new_data)\\n  return new_data \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def remove_round_brackets(data):\n",
    "  return re.sub('\\(.*?\\)','',data)\n",
    "\n",
    "def remove_punc(data):\n",
    "  trans = str.maketrans('','', string.punctuation)\n",
    "  return data.translate(trans)\n",
    "\n",
    "def white_space(data):\n",
    "  return ' '.join(data.split())\n",
    "\n",
    "def complete_noise(data):\n",
    "  new_data = remove_round_brackets(data)\n",
    "  new_data = remove_punc(new_data)\n",
    "  new_data = white_space(new_data)\n",
    "  return new_data \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" def Data_cleaning(x):\\n    return complete_noise(web_associated(x))\\n\\nfor index,row in labeled_question.iterrows():\\n    text = Data_cleaning(row['question'])\\n    #text1 = wordninja.split(text)\\n    #text2 = ' '.join(text1)\\n    labeled_question.loc[index,'question'] = text\\n\\ncleaned_labeled_question = labeled_question.loc[labeled_question['question'].str.len()>10]\\ncleaned_labeled_question.head()\\n \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def Data_cleaning(x):\n",
    "    return complete_noise(web_associated(x))\n",
    "\n",
    "for index,row in labeled_question.iterrows():\n",
    "    text = Data_cleaning(row['question'])\n",
    "    #text1 = wordninja.split(text)\n",
    "    #text2 = ' '.join(text1)\n",
    "    labeled_question.loc[index,'question'] = text\n",
    "\n",
    "cleaned_labeled_question = labeled_question.loc[labeled_question['question'].str.len()>10]\n",
    "cleaned_labeled_question.head()\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use custom web socket handler configure web so...</td>\n",
       "      <td>code like java configuration enable web socket...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>use higher version spring boot maven package l...</td>\n",
       "      <td>use higher version spring boot maven package l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>web flux functional endpoint authentication</td>\n",
       "      <td>found documentation authentication controller ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>document minimum supported version</td>\n",
       "      <td>deployed project made url address java followi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anyway override filter bean registration assoc...</td>\n",
       "      <td>existing couple spring application extends spr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1  use custom web socket handler configure web so...   \n",
       "3  use higher version spring boot maven package l...   \n",
       "4        web flux functional endpoint authentication   \n",
       "5                 document minimum supported version   \n",
       "6  anyway override filter bean registration assoc...   \n",
       "\n",
       "                                                body  label  \n",
       "1  code like java configuration enable web socket...      1  \n",
       "3  use higher version spring boot maven package l...      1  \n",
       "4  found documentation authentication controller ...      1  \n",
       "5  deployed project made url address java followi...      1  \n",
       "6  existing couple spring application extends spr...      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_labeled_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'code like java configuration enable web socket message broker public class web socket implement web socket message broker configure override public void register stomp endpoint stomp endpoint registry stomp endpoint registry stomp endpoint registry add endpoint web socket set allowed origin pattern add interceptor web socket interceptor bean public web socket handler web socket handler return new web socket handler bean public handshake interceptor web socket interceptor return new web socket interceptor default sub protocol web socket handler used want use custom web socket handler configure take effect'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_labeled_question.loc[1,'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    14545\n",
       "0    14198\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_labeled_question['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_labeled_question.to_csv('labeled_t+b_for_all.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_sample = cleaned_labeled_question.sample(3000)\n",
    "small_sample.to_csv('labeled_t+b_small_sample.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_sample = cleaned_labeled_question.sample(10000)\n",
    "mid_sample.to_csv('labeled_t+b_mid_sample.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5047\n",
       "0    4953\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1551\n",
       "0    1449\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = mid_sample['title'].to_list()\n",
    "ql = mid_sample['body'].to_list()\n",
    "comlst = []\n",
    "for i,j in zip(tl,ql):\n",
    "    com = i + j\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21df974e0a74f845a944bf5b01184a15d40dbbd4d60d49093b5b181fb3151fe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
